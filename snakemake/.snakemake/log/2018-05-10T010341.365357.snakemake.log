Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	12	down_sample_bams
	1	ref_all
	13

rule down_sample_bams:
    input: ../data/bam/1240k/KM4_allmerged_rmdup_reheader_1240k.trimmed.bam
    output: ../data/bam/1240k/downsampled/KM4_allmerged_rmdup_reheader_1240k_1x.trimmed.bam
    jobid: 10
    wildcards: id=KM4, coverage=1

Finished job 10.
1 of 13 steps (8%) done

rule down_sample_bams:
    input: ../data/bam/1240k/KM4_allmerged_rmdup_reheader_1240k.trimmed.bam
    output: ../data/bam/1240k/downsampled/KM4_allmerged_rmdup_reheader_1240k_0.1x.trimmed.bam
    jobid: 11
    wildcards: id=KM4, coverage=0.1

Finished job 11.
2 of 13 steps (15%) done

rule down_sample_bams:
    input: ../data/bam/1240k/KM4_allmerged_rmdup_reheader_1240k.trimmed.bam
    output: ../data/bam/1240k/downsampled/KM4_allmerged_rmdup_reheader_1240k_0.5x.trimmed.bam
    jobid: 6
    wildcards: id=KM4, coverage=0.5

Finished job 6.
3 of 13 steps (23%) done

rule down_sample_bams:
    input: ../data/bam/1240k/KM4_allmerged_rmdup_reheader_1240k.trimmed.bam
    output: ../data/bam/1240k/downsampled/KM4_allmerged_rmdup_reheader_1240k_2x.trimmed.bam
    jobid: 1
    wildcards: id=KM4, coverage=2

Terminating processes on user request, this might take some time.
Complete log: /project/jnovembre/chichun/ancient-imputation-experiment/snakemake/.snakemake/log/2018-05-10T010341.365357.snakemake.log
